{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fbea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import multiprocessing\n",
    "from good_tile_gan.generator import Generator\n",
    "from good_tile_gan.discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c4ec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1.0 / Number of CPU Cores: 24\n",
      "Training on NVIDIA GeForce RTX 4090 (cuda)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    n_gpu = float(torch.cuda.device_count())\n",
    "    device_name = torch.cuda.get_device_name(DEVICE)\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    device_name = \"Apple Silicon\"\n",
    "    n_gpu = 0.0\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    device_name = \"CPU\"\n",
    "    n_gpu = 0.0\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Number of GPUs: {n_gpu} / Number of CPU Cores: {n_cores}\")\n",
    "print(f\"Training on {device_name} ({DEVICE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_good_dir = \"./tile/train/good\"\n",
    "test_good_dir = \"./tile/test/good\"\n",
    "image_size = 256\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8044eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileDataset(Dataset):\n",
    "    def __init__(self, train_good_dir, test_good_dir, image_size):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.image_files = []\n",
    "\n",
    "        train_files = glob.glob(os.path.join(train_good_dir, '*.png'))\n",
    "        self.image_files.extend(train_files)\n",
    "        test_files = glob.glob(os.path.join(test_good_dir, '*.png')) \n",
    "        self.image_files.extend(test_files)\n",
    "        print(f\"- Found {len(train_files)} images in train_good_dir: {train_good_dir}\")\n",
    "        print(f\"- Found {len(test_files)} images in test_good_dir: {test_good_dir}\")\n",
    "        print(f\"-> Total {len(self.image_files)} 'good' samples collected.\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.Resize((self.image_size, self.image_size),\n",
    "                                  interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ])\n",
    "        print(\"Using default transforms (Resize, ToTensor, Normalize to [-1, 1]).\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        processed_image = self.transform(image)\n",
    "        return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e986ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Found 230 images in train_good_dir: ./tile/train/good\n",
      "- Found 33 images in test_good_dir: ./tile/test/good\n",
      "-> Total 263 'good' samples collected.\n",
      "Using default transforms (Resize, ToTensor, Normalize to [-1, 1]).\n"
     ]
    }
   ],
   "source": [
    "tile_dataset = TileDataset(train_good_dir, test_good_dir, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "        tile_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb22544",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "num_channels = 3\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "epochs = 800\n",
    "lr_g = 0.0002\n",
    "lr_d = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim, num_channels, image_size, ngf).to(DEVICE)\n",
    "discriminator = Discriminator(num_channels, image_size, ndf).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, beta2))\n",
    "\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=DEVICE)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, real_images in enumerate(dataloader):\n",
    "        real_images = real_images.to(DEVICE)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        real_label_val = 1.0\n",
    "        fake_label_val = 0.0\n",
    "        real_labels = torch.empty((batch_size,), device=DEVICE).fill_(real_label_val)\n",
    "        fake_labels = torch.empty((batch_size,), device=DEVICE).fill_(fake_label_val)\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        output_real = discriminator(real_images).view(-1)\n",
    "        errD_real = adversarial_loss(output_real, real_labels)\n",
    "        errD_real.backward()\n",
    "        D_x = output_real.mean().item()\n",
    "\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=DEVICE)\n",
    "        fake_images = generator(noise).detach()\n",
    "        output_fake = discriminator(fake_images).view(-1)\n",
    "        errD_fake = adversarial_loss(output_fake, fake_labels)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output_fake.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizer_D.step()\n",
    "\n",
    "        generator.zero_grad()\n",
    "\n",
    "        noise_for_G = torch.randn(batch_size, latent_dim, 1, 1, device=DEVICE)\n",
    "        fake_images_for_G = generator(noise_for_G)\n",
    "        output_G = discriminator(fake_images_for_G).view(-1)\n",
    "\n",
    "        errG = adversarial_loss(output_G, real_labels)\n",
    "\n",
    "        errG.backward()\n",
    "        D_G_z2 = output_G.mean().item()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                f'[{epoch+1}/{epochs}][{i}/{len(dataloader)}] '\n",
    "                f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
    "                f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}'\n",
    "            )\n",
    "\n",
    "print(\"Training Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "\n",
    "num_images_to_generate = 16\n",
    "noise = torch.randn(num_images_to_generate, latent_dim, 1, 1, device=DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_images = generator(noise).detach().cpu()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "output_filename = \"generated_tiles.png\"\n",
    "vutils.save_image(fake_images, output_filename, normalize=True, nrow=4)\n",
    "print(f\"Saved generated images to {output_filename}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "grid = vutils.make_grid(fake_images, nrow=4, normalize=True)\n",
    "img_to_show = F.to_pil_image(grid)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_to_show)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Tiles\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
