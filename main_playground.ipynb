{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcced85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils.get_img_paths import get_img_paths\n",
    "from utils.tile_dataset import TileDataset\n",
    "from utils.generator import UNetGenerator\n",
    "from utils.discriminator import PatchGANDiscriminator\n",
    "from utils.training import train_conditional_gan\n",
    "from utils.weights_init import weights_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0b7605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1.0 / Number of CPU Cores: 24\n",
      "Training on NVIDIA GeForce RTX 4090 (cuda)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    n_gpu = float(torch.cuda.device_count())\n",
    "    device_name = torch.cuda.get_device_name(DEVICE)\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    device_name = \"Apple Silicon\"\n",
    "    n_gpu = 0.0\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    device_name = \"CPU\"\n",
    "    n_gpu = 0.0\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Number of GPUs: {n_gpu} / Number of CPU Cores: {n_cores}\")\n",
    "print(f\"Training on {device_name} ({DEVICE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab77a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_DIR = \"./tile/ground_truth\"\n",
    "ANOMALY_TYPES_TO_TRAIN = [\"crack\", \"glue_strip\"]\n",
    "IMG_SIZE = 256 \n",
    "NUM_CHANNELS = 3     # Image channels (RGB)\n",
    "NUM_CLASSES = len(ANOMALY_TYPES_TO_TRAIN) # Number of defect conditions\n",
    "EMBED_SIZE = 16      # Size of the condition embedding vector (in G and D)\n",
    "NGF = 64             # Base number of features for Generator\n",
    "NDF = 64             # Base number of features for Discriminator\n",
    "BATCH_SIZE = 32      # Adjust based on VRAM\n",
    "EPOCHS = 300         # Number of training epochs\n",
    "LR_G = 0.0002        # Learning rate for Generator\n",
    "LR_D = 0.0002        # Learning rate for Discriminator\n",
    "BETA1 = 0.5          # Adam optimizer beta1\n",
    "BETA2 = 0.999        # Adam optimizer beta2\n",
    "LAMBDA_L1 = 50.0\n",
    "NUM_WORKERS = round(n_cores*0.7)\n",
    "\n",
    "CHECKPOINT_DIR = \"./checkpoints_cgan_tile\" # Directory to save model checkpoints\n",
    "SAMPLE_DIR = \"./samples_cgan_tile\"         # Directory to save generated image samples\n",
    "SAVE_CHECKPOINT_FREQ = 30             # Save checkpoints every N epochs\n",
    "SAVE_SAMPLES_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5296319",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = {\n",
    "    \"crack\": [], \"glue_strip\": [], \"gray_stroke\": [],\n",
    "    \"oil\": [], \"rough\": [], \"good\": []\n",
    "}\n",
    "\n",
    "img_paths = get_img_paths(paths=img_paths, subfolder=\"train\")\n",
    "img_paths = get_img_paths(paths=img_paths, subfolder=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e95f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: crack\n",
      "  -> Added 17 samples for anomaly type 'crack'.\n",
      "Processing category: glue_strip\n",
      "  -> Added 18 samples for anomaly type 'glue_strip'.\n",
      "Processing category: good\n",
      "  -> Added 263 'good' samples.\n",
      "-> Total 298 samples prepared for the dataset.\n"
     ]
    }
   ],
   "source": [
    "conditional_dataset = TileDataset(\n",
    "    image_paths_dict=img_paths,\n",
    "    mask_base_dir=MASK_DIR,\n",
    "    anomaly_types_for_training=ANOMALY_TYPES_TO_TRAIN,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "conditional_dataloader = DataLoader(\n",
    "    conditional_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a690e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNetGenerator(num_classes=NUM_CLASSES, embed_size=16).to(DEVICE)\n",
    "discriminator = PatchGANDiscriminator(num_classes=NUM_CLASSES, embed_size=16).to(DEVICE)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LR_G, betas=(BETA1, BETA2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LR_D, betas=(BETA1, BETA2))\n",
    "\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "reconstruction_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "020e24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fixed batch of size 32 for visualization.\n"
     ]
    }
   ],
   "source": [
    "fixed_batch_for_vis = None\n",
    "try:\n",
    "    fixed_batch_for_vis = next(iter(conditional_dataloader))\n",
    "    print(f\"Using fixed batch of size {fixed_batch_for_vis[0].size(0)} for visualization.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not get fixed batch for visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e69207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Conditional GAN Training for 300 epochs on cuda...\n",
      "Using fixed batch of size 32 for visualization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff90d8500320497d960243b0e12a8b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total Training Progress:   0%|          | 0/2700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished after 300 epochs.\n"
     ]
    }
   ],
   "source": [
    "train_conditional_gan(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    dataloader=conditional_dataloader,\n",
    "    optimizer_G=optimizer_G,\n",
    "    optimizer_D=optimizer_D,\n",
    "    adversarial_loss=adversarial_loss,\n",
    "    reconstruction_loss=reconstruction_loss,\n",
    "    lambda_l1=LAMBDA_L1,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    fixed_batch_for_vis=fixed_batch_for_vis,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    sample_dir=SAMPLE_DIR,\n",
    "    save_checkpoint_freq=SAVE_CHECKPOINT_FREQ,\n",
    "    save_samples_freq=SAVE_SAMPLES_FREQ\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
